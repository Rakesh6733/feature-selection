{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPirh7T6Zs+J6DOncxlrj//"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KVVtx8FLQRz0"},"outputs":[],"source":["import pandas as pd"]},{"cell_type":"code","source":["df1 = pd.read_csv(\"/content/drive/MyDrive/data.csv\")"],"metadata":{"id":"6LJVNW8FQTtA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","df1.replace([np.inf, -np.inf], np.nan, inplace=True)\n","\n","# Dropping all the rows with nan values\n","df1.dropna(inplace=True)\n","df1.isin([np.inf, -np.inf]).sum()\n","data=df1"],"metadata":{"id":"FfNt_KSHQTwB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = data.iloc[:,:-1]\n","y = data.iloc[:,-1]"],"metadata":{"id":"xhHL50iQQTzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","x_f = scaler.fit_transform(x)"],"metadata":{"id":"1tOXiIdjQT2U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","l = LabelEncoder()\n","u = l.fit_transform(y)"],"metadata":{"id":"sD7BwqFbQT5b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NL = pd.DataFrame(x_f)\n","L = pd.DataFrame(u)\n","data = pd.concat([NL, L], axis=1)"],"metadata":{"id":"W0QhAvS3QT8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(0,78):\n","  globals()[f\"d{i}\"] = data.iloc[:,i].astype(\"float32\")"],"metadata":{"id":"LjxE7EeGQT_5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d78 = data.iloc[:,-1].astype('int8')"],"metadata":{"id":"Gu8RrE_xQUDD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","data = pd.concat([d0,d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23,d24,d25,d26,d27,d28,d29,d30,d31,d32,d33,d34,d35,d36,d37,d38,d39,d40,d41,d42,d43,d44,d45,d46,d47,d48,d49,d50,d51,d52,d53,d54,d55,d56,d57,d58,d59,d60,d61,d62,d63,d64,d65,d66,d67,d68,d69,d70,d71,d72,d73,d74,d75,d76,d77,d78], axis=1)"],"metadata":{"id":"UNJHXb5rQUGZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["      #4,5,6,7,8\n","d_1 = data.iloc[:,0]\n","d_2 = data.iloc[:,1]\n","d_3 = data.iloc[:,2]\n","d_4 = data.iloc[:,3]\n","d_5 = data.iloc[:,4]\n","#10,11,12,14,15\n","d_6 = data.iloc[:,5]\n","d_7 = data.iloc[:,6]\n","d_8 = data.iloc[:,7]\n","d_9 = data.iloc[:,27]\n","d_10 = data.iloc[:,9]\n","#22,24,25\n","d_11 = data.iloc[:,10]\n","d_12 = data.iloc[:,11]\n","d_13 = data.iloc[:,12]\n","d_14 = data.iloc[:,13]\n","d_15 = data.iloc[:,14]\n","#55,56,57\n","d_16 = data.iloc[:,15]\n","d_17 = data.iloc[:,16]\n","d_18 = data.iloc[:,17]\n","#64,65,66,67,68,69\n","d_19 = data.iloc[:,18]\n","d_20 = data.iloc[:,19]     #[0, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n","                            # 20, 21, 22, 24, 25, 27, 28, 29, 30, 37, 38, 39, 40, 41, 47, 49, 52, 53, 54, 55, 63, 64, 66, 67, 68, 69, 72, 77] --> 48\n","d_21 = data.iloc[:,20]\n","d_22 = data.iloc[:,21]\n","d_23 = data.iloc[:,22]\n","d_24 = data.iloc[:,24]\n","d_25 = data.iloc[:,25]\n","d_26 = data.iloc[:,28]\n","d_27 = data.iloc[:,29]\n","d_28 = data.iloc[:,30]\n","d_29 = data.iloc[:,37]\n","d_30 = data.iloc[:,38]\n","d_31 = data.iloc[:,39]\n","d_32 = data.iloc[:,40]\n","d_33 = data.iloc[:,41]\n","d_34 = data.iloc[:,47]\n","d_35 = data.iloc[:,49]\n","d_36 = data.iloc[:,52]\n","d_37 = data.iloc[:,53]\n","d_38 = data.iloc[:,54]\n","d_39 = data.iloc[:,55]\n","d_40 = data.iloc[:,63]\n","d_41 = data.iloc[:,64]\n","d_42 = data.iloc[:,66]\n","d_43 = data.iloc[:,67]\n","d_44 = data.iloc[:,68]\n","d_45 = data.iloc[:,69]\n","d_46 = data.iloc[:,72]\n","d_47 = data.iloc[:,77]\n","\n","#[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 28, 30, 37, 38, 39, 40, 41, 44, 47, 49, 52, 53, 54, 55, 64, 65, 67, 68, 69, 72, 74, 75]"],"metadata":{"id":"VcPT9_4hQUK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = pd.DataFrame([d_1,d_2,d_3,d_4,d_5,d_6,d_7,d_8,d_9,d_10,d_11,d_12,d_13,d_14,d_15,d_16,d_17,d_18,d_19,d_20,d_21,d_22,d_23,d_24,d_25,d_26,d_27,d_28,d_29,d_30,d_31,d_32,d_33,d_34,d_35,d_36,d_37,d_38,d_39,d_40,d_41,d_42,d_43,d_44,d_45,d_46,d_47,d78])"],"metadata":{"id":"nJ7n-CVqQUOf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["network_data=data.T\n","clean_data = network_data.dropna()\n","clean_data.reset_index(inplace=True, drop=True)"],"metadata":{"id":"_AJCnBzYQtWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","data_1 = u[u == 0]\n","data_2 = u[u == 1]\n","data_3 = u[u == 2]\n","data_4 = u[u == 3]\n","data_5 = u[u == 4]\n","data_6 = u[u == 5]\n","data_7 = u[u == 6]\n","\n","\n","# make benign feature\n","y_1 = np.zeros(data_1.shape[0])\n","y_benign = pd.DataFrame(y_1)\n","\n","# make bruteforce feature\n","y_2 = np.ones(data_2.shape[0])\n","y_bf = pd.DataFrame(y_2)\n","\n","# make bruteforceSSH feature\n","y_3 = np.full(data_3.shape[0], 2)\n","y_ssh = pd.DataFrame(y_3)\n","\n","y_4 = np.full(data_4.shape[0], 2)\n","y_ssh1 = pd.DataFrame(y_4)\n","\n","y_5 = np.full(data_5.shape[0], 2)\n","y_ssh2 = pd.DataFrame(y_5)\n","\n","y_6 = np.full(data_6.shape[0], 2)\n","y_ssh3 = pd.DataFrame(y_6)\n","\n","y_7 = np.full(data_7.shape[0], 2)\n","y_ssh4 = pd.DataFrame(y_7)\n","\n","\n","# merging the original dataframe\n","y = pd.concat([y_benign, y_bf, y_ssh,y_ssh1,y_ssh2,y_ssh3,y_ssh4], sort=True).reset_index(drop=True)\n","y = u/6.0\n","x = clean_data.iloc[:,:-1]\n","from keras.utils.np_utils import to_categorical\n","\n","y = to_categorical(y,num_classes=7)\n","from sklearn.preprocessing import LabelEncoder\n","l = LabelEncoder()\n","u = l.fit_transform(clean_data.iloc[:,-1])"],"metadata":{"id":"GH3DcyaOQtaE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","data_1 = u[u == 0]\n","data_2 = u[u == 1]\n","data_3 = u[u == 2]\n","data_4 = u[u == 3]\n","data_5 = u[u == 4]\n","data_6 = u[u == 5]\n","data_7 = u[u == 6]\n","\n","\n","# make benign feature\n","y_1 = np.zeros(data_1.shape[0])\n","y_benign = pd.DataFrame(y_1)\n","\n","# make bruteforce feature\n","y_2 = np.ones(data_2.shape[0])\n","y_bf = pd.DataFrame(y_2)\n","\n","# make bruteforceSSH feature\n","y_3 = np.full(data_3.shape[0], 2)\n","y_ssh = pd.DataFrame(y_3)\n","\n","y_4 = np.full(data_4.shape[0], 2)\n","y_ssh1 = pd.DataFrame(y_4)\n","\n","y_5 = np.full(data_5.shape[0], 2)\n","y_ssh2 = pd.DataFrame(y_5)\n","\n","y_6 = np.full(data_6.shape[0], 2)\n","y_ssh3 = pd.DataFrame(y_6)\n","\n","y_7 = np.full(data_7.shape[0], 2)\n","y_ssh4 = pd.DataFrame(y_7)\n","\n","\n","# merging the original dataframe\n","y = pd.concat([y_benign, y_bf, y_ssh,y_ssh1,y_ssh2,y_ssh3,y_ssh4], sort=True).reset_index(drop=True)\n","x = clean_data.iloc[:,:-1]\n","y =u\n","x = np.array(x)\n","y = np.array(u)\n","from keras.utils.np_utils import to_categorical\n","\n","y = to_categorical(y,num_classes=7)"],"metadata":{"id":"zR200HqgQtdJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"fW2fS0TZQtf-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"otBtiM3KQtis"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"I6aKkBsHQtl_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XZ2ND_6WQtpI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2IBL3ZnCQURo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow import keras\n","import numpy as np\n","\n","# Encoder\n","encoder_input = keras.Input(shape=(47, 1))\n","encoder = keras.layers.LSTM(2048, return_sequences=True)(encoder_input)\n","encoder = keras.layers.LSTM(1024, return_sequences=True)(encoder)\n","encoder = keras.layers.LSTM(512, return_sequences=True)(encoder)\n","encoder = keras.layers.LSTM(256, return_sequences=True)(encoder)\n","encoder = keras.layers.LSTM(128, return_sequences=True)(encoder)\n","encoder = keras.layers.LSTM(64, return_sequences=False)(encoder)\n","encoder_output = keras.layers.Dense(32, activation='relu')(encoder)\n","encoder_model = keras.Model(encoder_input, encoder_output)\n","\n","# Decoder\n","decoder_input = keras.Input(shape=(32,))\n","decoder = keras.layers.RepeatVector(47)(decoder_input)\n","decoder = keras.layers.LSTM(64, return_sequences=True)(decoder)\n","decoder = keras.layers.LSTM(128, return_sequences=True)(decoder)\n","decoder = keras.layers.LSTM(256, return_sequences=True)(decoder)\n","decoder = keras.layers.LSTM(512, return_sequences=True)(decoder)\n","decoder = keras.layers.LSTM(1024, return_sequences=True)(decoder)\n","decoder = keras.layers.LSTM(2048, return_sequences=True)(decoder)\n","decoder_output = keras.layers.TimeDistributed(keras.layers.Dense(1))(decoder)\n","decoder_model = keras.Model(decoder_input, decoder_output)\n","\n","# Autoencoder\n","autoencoder_input = keras.Input(shape=(47, 1))\n","encoded = encoder_model(autoencoder_input)\n","decoded = decoder_model(encoded)\n","autoencoder = keras.Model(autoencoder_input, decoded)\n","\n","# Compile and train the autoencoder\n","autoencoder.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","\n","# autoencoder.fit(x_data, x_data, batch_size=256, epochs=500, validation_split=0.2)\n","\n"],"metadata":{"id":"ifVVWQ2yQUVj"},"execution_count":null,"outputs":[]}]}