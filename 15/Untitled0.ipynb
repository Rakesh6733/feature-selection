{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOg12t0Zunbpg3M24BrTeKT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cwC3KoJcXsr","executionInfo":{"status":"ok","timestamp":1678802812820,"user_tz":-330,"elapsed":25937,"user":{"displayName":"mukesh reddy pochamreddy","userId":"11251314162381263295"}},"outputId":"522bc6b5-49e0-4543-8f90-98db6bce8608"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":365},"id":"V_FzW1gScOiz","executionInfo":{"status":"error","timestamp":1678802982829,"user_tz":-330,"elapsed":10220,"user":{"displayName":"mukesh reddy pochamreddy","userId":"11251314162381263295"}},"outputId":"474becd2-0391-44a3-ac6c-44a4a6c7755a"},"outputs":[{"output_type":"error","ename":"MemoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-888336292bbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Split the data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/np_utils.py\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes, dtype)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 227. TiB for an array with shape (520715, 120000001) and data type float32"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten\n","from keras.utils import to_categorical\n","\n","# Load the data\n","df = pd.read_csv('/content/drive/MyDrive/data.csv')\n","\n","d1 = df.iloc[:,0]\n","d4 = df.iloc[:,3]\n","d6 = df.iloc[:,5]\n","d70 = df.iloc[:,69]\n","d72 = df.iloc[:,71]\n","d73 = df.iloc[:,72]\n","d48 = df.iloc[:,47]\n","d69 = df.iloc[:,68]\n","d8 = df.iloc[:,7]\n","d30 = df.iloc[:,29]\n","d76 = df.iloc[:,28]\n","d12 = df.iloc[:,11]\n","d25 = df.iloc[:,24]\n","d6 = df.iloc[:,59]\n","d79 = df.iloc[:,78]\n","\n","dfea = pd.DataFrame([d1,d4,d6,d70,d72,d73,d48,d69,d8,d30,d76,d12,d25,d6,d79])\n","network_data=dfea.T\n","clean_data = network_data.dropna()\n","import numpy as np\n","clean_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n","  \n","# Dropping all the rows with nan values\n","clean_data.dropna(inplace=True)\n","\n","# Preprocess the data\n","scaler = StandardScaler()\n","X = clean_data.iloc[:, :-1].values\n","X = scaler.fit_transform(X)\n","y = clean_data.iloc[:, -1].values\n","y = to_categorical(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Reshape the data for use with a 1D CNN\n","X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n","X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n","\n","# Define the CNN model\n","model = Sequential()\n","model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)))\n","model.add(MaxPooling1D(pool_size=2))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(y_train.shape[1], activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n","\n","# Evaluate the model on the test set\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print(\"Test loss:\", loss)\n","print(\"Test accuracy:\", accuracy)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"YWm_mkMJclWx"},"execution_count":null,"outputs":[]}]}